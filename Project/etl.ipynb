{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL (Extract Transform Load) Script for getting the data. We first scrape the data using bs4. We can use pandas, since its a one-off, small-size script. Afterwards we get the election data and process them and merge them together into a single csv.\n",
    "### TODO how did we get the gemeinden list?\n",
    "### todo is this webscaping script good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8250e320a80b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Construct URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgemeinde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL\n",
    "base_url = 'https://vrv97.offenerhaushalt.at/gemeinde/{}/finanzdaten/hauptansicht/unterricht-erziehung-sport-und-wissenschaft/absolut/{}/ausgaben'\n",
    "\n",
    "# List of municipalities\n",
    "gemeinden = [\n",
    "   \"adlwang\", \"aichkirchen\", \"aigen-schlägl\", \"aistersheim\", \"alberndorf-in-der-riedmark\",\n",
    "    \"alkoven\", \"allerheiligen-im-mühlkreis\", \"allhaming\", \"altenberg-bei-linz\", \"altenfelden\",\n",
    "    \"altheim\", \"altmünster\", \"altschwendt\", \"ampflwang-im-hausruckwald\", \"andorf\", \"andrichsfurt\",\n",
    "    \"ansfelden\", \"antiesenhofen\", \"arbing\", \"arnreit\", \"aschach-an-der-donau\", \"aschach-an-der-steyr\",\n",
    "    \"aspach\", \"asten\", \"attersee-am-attersee\", \"attnang-puchheim\", \"atzbach\", \"atzesberg\", \n",
    "    \"auberg\", \"auerbach\", \"aurach-am-hongar\", \"aurolzmünster\", \"bachmanning\", \n",
    "    \"bad-goisern-am-hallstättersee\", \"bad-hall\", \"bad-ischl\", \"bad-kreuzen\", \"bad-leonfelden\", \n",
    "    \"bad-schallerbach\", \"bad-wimsbach-neydharting\", \"bad-zell\", \"baumgartenberg\", \n",
    "    \"berg-im-attergau\", \"braunau-am-inn\", \"brunnenthal\", \"buchkirchen\", \"burgkirchen\", \n",
    "    \"desselbrunn\", \"diersbach\", \"dietach\", \"dimbach\", \"dorf-an-der-pram\", \"ebensee-am-traunsee\", \n",
    "    \"eberschwang\", \"eberstalzell\", \"edlbach\", \"edt-bei-lambach\", \"eferding\", \"eggelsberg\", \n",
    "    \"eggendorf-im-traunkreis\", \"eggerding\", \"eidenberg\", \"eitzing\", \"engelhartszell-an-der-donau\", \n",
    "    \"engerwitzdorf\", \"enns\", \"enzenkirchen\", \"eschenau-im-hausruckkreis\", \"esternberg\", \n",
    "    \"feldkirchen-an-der-donau\", \"feldkirchen-bei-mattighofen\", \"fischlham\", \"fornach\", \n",
    "    \"fraham\", \"frankenburg-am-hausruck\", \"frankenmarkt\", \"franking\", \"freinberg\", \n",
    "    \"freistadt\", \"gaflenz\", \"gallneukirchen\", \"gallspach\", \"gampern\", \"garsten\", \n",
    "    \"gaspoltshofen\", \"geboltskirchen\", \"geiersberg\", \"geinberg\", \"geretsberg\", \n",
    "    \"gilgenberg-am-weilhart\", \"gmunden\", \"goldwörth\", \"gosau\", \"gramastetten\", \"grein\", \n",
    "    \"grieskirchen\", \"großraming\", \"grünau-im-almtal\", \"grünbach\", \"grünburg\", \"gschwandt\", \n",
    "    \"gunskirchen\", \"gurten\", \"gutau\", \"haag-am-hausruck\", \"hagenberg-im-mühlkreis\", \n",
    "    \"haibach-im-mühlkreis\", \"haibach-ob-der-donau\", \"haigermoos\", \"hallstatt\", \"handenberg\", \n",
    "    \"hargelsberg\", \"hartkirchen\", \"haslach-an-der-mühl\", \"heiligenberg\", \"helfenberg\", \n",
    "    \"hellmonsödt\", \"helpfau-uttendorf\", \"herzogsdorf\", \"hinterstoder\", \"hinzenbach\", \n",
    "    \"hirschbach-im-mühlkreis\", \"hochburg-ach\", \"hofkirchen-an-der-trattnach\", \n",
    "    \"hofkirchen-im-mühlkreis\", \"hofkirchen-im-traunkreis\", \"hohenzell\", \"höhnhart\", \n",
    "    \"holzhausen\", \"hörbich\", \"hörsching\", \"innerschwand-am-mondsee\", \"inzersdorf-im-kremstal\", \n",
    "    \"jeging\", \"julbach\",\"kallham\", \"kaltenberg\", \"katsdorf\", \"kefermarkt\", \"kematen-am-innbach\", \"kematen-an-der-krems\", \n",
    "\"kirchberg-bei-mattighofen\", \"kirchberg-ob-der-donau\", \"kirchberg-thening\", \"kirchdorf-am-inn\", \n",
    "\"kirchdorf-an-der-krems\", \"kirchham\", \"kirchheim-im-innkreis\", \"kirchschlag-bei-linz\", \n",
    "\"klaffer-am-hochficht\", \"klam\", \"klaus-an-der-pyhrnbahn\", \"kleinzell-im-mühlkreis\", \n",
    "\"kollerschlag\", \"königswiesen\", \"kopfing-im-innkreis\", \"kremsmünster\", \"krenglbach\", \n",
    "\"kronstorf\", \"laakirchen\", \"lambach\", \"lambrechten\", \"langenstein\", \"lasberg\", \n",
    "\"laussa\", \"lembach-im-mühlkreis\", \"lengau\", \"lenzing-an-der-ager\", \"leonding\", \n",
    "\"leopoldschlag\", \"lichtenau-im-mühlkreis\", \"lichtenberg\", \"liebenau\", \"linz\", \n",
    "\"lochen-am-see\", \"lohnsburg-am-kobernaußerwald\", \"losenstein\", \"luftenberg-an-der-donau\", \n",
    "\"manning\", \"marchtrenk\", \"maria-neustift\", \"maria-schmolln\", \"mattighofen\", \n",
    "\"mauerkirchen\", \"mauthausen\", \"mayrhof\", \"meggenhofen\", \"mehrnbach\", \"mettmach\", \n",
    "\"michaelnbach\", \"micheldorf-in-oberösterreich\", \"mining\", \"mitterkirchen-im-machland\", \n",
    "\"molln\", \"mondsee\", \"moosbach\", \"moosdorf\", \"mörschwang\", \"mühlheim-am-inn\", \n",
    "\"munderfing\", \"münzbach\", \"münzkirchen\" \"naarn-im-machlande\", \"natternbach\", \"nebelberg\", \"neufelden\", \"neuhofen-an-der-krems\", \n",
    "    \"neuhofen-im-innkreis\", \"neukirchen-am-walde\", \"neukirchen-an-der-enknach\", \n",
    "    \"neukirchen-an-der-vöckla\", \"neukirchen-bei-lambach\", \"neumarkt-im-hausruckkreis\", \n",
    "    \"neumarkt-im-mühlkreis\", \"neustift-im-mühlkreis\", \"niederkappel\", \"niederneukirchen\", \n",
    "    \"niederthalheim\", \"niederwaldkirchen\", \"nussbach\", \"nussdorf-am-attersee\", \n",
    "    \"oberhofen-am-irrsee\", \"oberkappel\", \"obernberg-am-inn\", \"oberndorf-bei-schwanenstadt\", \n",
    "    \"oberneukirchen\", \"oberschlierbach\", \"obertraun\", \"oberwang\", \"oepping\", \"offenhausen\", \n",
    "    \"oftering\", \"ohlsdorf\", \"ort-im-innkreis\", \"ostermiething\", \"ottenschlag-im-mühlkreis\", \n",
    "    \"ottensheim\", \"ottnang-am-hausruck\", \"pabneukirchen\", \"palting\", \"pasching\", \"pattigham\", \n",
    "    \"peilstein-im-mühlviertel\", \"pennewang\", \"perg\", \"perwang-am-grabensee\", \"peterskirchen\", \n",
    "    \"pettenbach\", \"peuerbach\", \"pfaffing\", \"pfaffstätt\", \"pfarrkirchen-bei-bad-hall\", \n",
    "    \"pfarrkirchen-im-mühlkreis\", \"piberbach\", \"pichl-bei-wels\", \"pierbach\", \"pilsbach\", \n",
    "    \"pinsdorf\", \"pischelsdorf-am-engelbach\", \"pitzenberg\", \"pollham\", \"polling-im-innkreis\", \n",
    "    \"pöndorf\", \"pötting\", \"pram\", \"prambachkirchen\", \"pramet\", \"pregarten\", \"puchenau\", \n",
    "    \"puchkirchen-am-trattberg\", \"pucking\", \"pühret\", \"pupping\", \"putzleinsdorf\", \"raab\", \n",
    "    \"rainbach-im-innkreis\", \"rainbach-im-mühlkreis\", \"rechberg\", \"redleiten\", \"redlham\", \n",
    "    \"regau\", \"reichenau-im-mühlkreis\", \"reichenthal\", \"reichersberg\", \"reichraming\", \n",
    "    \"ried-im-innkreis\", \"ried-im-traunkreis\", \"ried-in-der-riedmark\", \"riedau\", \n",
    "    \"rohr-im-kremstal\", \"rohrbach-berg\", \"roitham-am-traunfall\", \"rosenau-am-hengstpass\", \n",
    "    \"rossbach\", \"rossleithen\", \"rottenbach\", \"rüstorf\", \"rutzenham\", \"sandl\", \"sarleinsbach\", \n",
    "    \"sattledt\", \"saxen\", \"schalchen\"\"schardenberg\", \"schärding\", \"scharnstein\", \"scharten\", \"schenkenfelden\", \"schiedlberg\", \"schildorn\", \"schlatt\", \"schleißheim\", \"schlierbach\", \"schlüsslberg\", \"schönau-im-mühlkreis\", \"schörfling-am-attersee\", \"schwand-im-innkreis\", \"schwanenstadt\", \"schwarzenberg-am-böhmerwald\", \"schwertberg\", \"seewalchen-am-attersee\", \"senftenbach\", \"sierning\", \"sigharting\", \"sipbachzell\", \"sonnberg-im-mühlkreis\", \"spital-am-pyhrn\", \"st-aegidi\", \"st-agatha\", \"st-florian\", \"st-florian-am-inn\", \"st-georgen-am-fillmannsbach\", \"st-georgen-am-walde\", \"st-georgen-an-der-gusen\", \"st-georgen-bei-grieskirchen\", \"st-georgen-bei-obernberg-am-inn\", \"st-georgen-im-attergau\", \"st-gotthard-im-mühlkreis\", \"st-johann-am-walde\", \"st-johann-am-wimberg\", \"st-konrad\", \"st-leonhard-bei-freistadt\", \"st-lorenz\", \"st-marien\", \"st-marienkirchen-am-hausruck\", \"st-marienkirchen-an-der-polsenz\", \"st-marienkirchen-bei-schärding\", \"st-martin-im-innkreis\", \"st-martin-im-mühlkreis\", \"st-nikola-an-der-donau\", \"st-oswald-bei-freistadt\", \"st-oswald-bei-haslach\", \"st-pankraz\", \"st-pantaleon\", \"st-peter-am-hart\", \"st-peter-am-wimberg\", \"st-radegund\", \"st-roman\", \"st-stefan-afiesl\", \"st-thomas\", \"st-thomas-am-blasenstein\", \"st-ulrich-bei-steyr\", \"st-ulrich-im-mühlkreis\", \"st-veit-im-innkreis\", \"st-veit-im-mühlkreis\", \"st-willibald\", \"st-wolfgang-im-salzkammergut\", \"stadl-paura\", \"steegen\", \"steinbach-am-attersee\", \"steinbach-am-ziehberg\", \"steinbach-an-der-steyr\", \"steinerkirchen-an-der-traun\", \"steinhaus\", \"steyr\", \"steyregg\", \"straß-im-attergau\", \"stroheim\", \"suben\", \"taiskirchen-im-innkreis\", \"tarsdorf\", \"taufkirchen-an-der-pram\", \"taufkirchen-an-der-trattnach\", \"ternberg\", \"thalheim-bei-wels\", \"tiefgraben\", \"timelkam\", \"tollet\", \"tragwein\", \"traun\", \"traunkirchen\", \"treubach\", \"tumeltsham\", \"überackern\", \"ulrichsberg\", \"ungenach\", \"unterach-am-attersee\", \"unterweißenbach\", \"unterweitersdorf\", \"utzenaich\", \"vichtenstein\", \"vöcklabruck\", \"vöcklamarkt\", \"vorchdorf\", \"vorderstoder\", \"vorderweißenbach\", \"waizenkirchen\", \"waldburg\", \"waldhausen-im-strudengau\", \"walding\", \"waldkirchen-am-wesen\", \"waldneukirchen\", \"waldzell\", \"wallern-an-der-trattnach\", \"wartberg-an-der-krems\", \"wartberg-ob-der-aist\", \"weibern\", \"weilbach\", \"weißenkirchen-im-attergau\", \"weißkirchen-an-der-traun\", \"weitersfelden\", \"wels\", \"wendling\", \"weng-im-innkreis\", \"wernstein-am-inn\", \"weyer\", \"weyregg-am-attersee\", \"wilhering\", \"windhaag-bei-freistadt\", \"windhaag-bei-perg\", \"windischgarsten\", \"wippenham\", \"wolfern\", \"wolfsegg-am-hausruck\", \"zell-am-moos\", \"zell-am-pettenfirst\", \"zell-an-der-pram\", \"zwettl-an-der-rod\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# Loop through each municipality\n",
    "for gemeinde in gemeinden:\n",
    "    # Loop through the years from 2007 to 2019\n",
    "    for year in range(2007, 2020):\n",
    "        # Construct URL\n",
    "        url = base_url.format(gemeinde, year)\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the specific div by ID\n",
    "            treemap_div_id = f'treemap-table-{year}'\n",
    "            treemap_div = soup.find('div', id=treemap_div_id)\n",
    "            if treemap_div:\n",
    "                # Find the table within the div\n",
    "                table = treemap_div.find('table')\n",
    "                if table:\n",
    "                    # Iterate through each row in the table body\n",
    "                    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "                        columns = row.find_all('td')\n",
    "                        if len(columns) >= 3:  # Ensure there are enough columns\n",
    "                            section = columns[1].get_text(strip=True)  # \"Abschnitt\"\n",
    "                            amount = columns[2].find('span', class_='value-value').get_text(strip=True)  # \"Betrag in Euro\"\n",
    "                            all_data.append({'Gemeinde': gemeinde, 'Year': year, 'Abschnitt': section, 'Betrag in Euro': amount})\n",
    "                else:\n",
    "                    print(f\"No data table found for {gemeinde} in year {year}.\")\n",
    "            else:\n",
    "                print(f\"No data available for {gemeinde} in year {year}. The div with ID 'treemap-table-2019' was not found.\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for {gemeinde} in year {year}. Status code: {response.status_code}\")\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv('Bildungsausgaben_Gemeinden_Oberösterreich_data_2007_bis_2019(1).csv', index=False)\n",
    "print(\"Data has been scraped and saved to 'Bildungsausgaben_Gemeinden_Oberösterreich_data_2007_bis_2019.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we get the data for the elections. We will use spark from now on, to ensure scalability.\n",
    "\n",
    "### TODO how did we get election data\n",
    "\n",
    "Since the election data was originally provided in an inconsistent XLS format—with irregular merged cells, random empty lines, and other structural issues—we manually formatted the data to ensure consistency and saved it as an XLSX file for better usability.\n",
    "\n",
    "Since we had only 5 XLS files for election data, this was the easiest option. However, this can be automated using a script for formatting if we were to automate and scale this project. However, this is out of scope for now.\n",
    "\n",
    "Afterwards, we used a small script to convert these XLSX files to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: OÖ 2017.xlsx (Sheet: Stimmen) -> /home/jovyan/DP2/Project/data/OÖ_2017_Stimmen.csv\n",
      "Converted: OÖ 2017.xlsx (Sheet: Mandate) -> /home/jovyan/DP2/Project/data/OÖ_2017_Mandate.csv\n",
      "Converted: OÖ 2019.xlsx (Sheet: Stimmen) -> /home/jovyan/DP2/Project/data/OÖ_2019_Stimmen.csv\n",
      "Converted: OÖ 2019.xlsx (Sheet: Mandate) -> /home/jovyan/DP2/Project/data/OÖ_2019_Mandate.csv\n",
      "Converted: OÖ 2024.xlsx (Sheet: Stimmen) -> /home/jovyan/DP2/Project/data/OÖ_2024_Stimmen.csv\n",
      "Converted: OÖ 2024.xlsx (Sheet: Mandate) -> /home/jovyan/DP2/Project/data/OÖ_2024_Mandate.csv\n",
      "Converted: OÖ 2008.xlsx (Sheet: Stimmen) -> /home/jovyan/DP2/Project/data/OÖ_2008_Stimmen.csv\n",
      "Converted: OÖ 2008.xlsx (Sheet: Mandate) -> /home/jovyan/DP2/Project/data/OÖ_2008_Mandate.csv\n",
      "Converted: OÖ 2013.xlsx (Sheet: Stimmen) -> /home/jovyan/DP2/Project/data/OÖ_2013_Stimmen.csv\n",
      "Converted: OÖ 2013.xlsx (Sheet: Mandate) -> /home/jovyan/DP2/Project/data/OÖ_2013_Mandate.csv\n",
      "Converted: OÖ 2013.xlsx (Sheet: whlsortgemnr) -> /home/jovyan/DP2/Project/data/OÖ_2013_whlsortgemnr.csv\n",
      "Converted: OÖ 2013.xlsx (Sheet: MandateData) -> /home/jovyan/DP2/Project/data/OÖ_2013_MandateData.csv\n",
      "Converted: OÖ 2013.xlsx (Sheet: WAHLDAT) -> /home/jovyan/DP2/Project/data/OÖ_2013_WAHLDAT.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "# Get all .xlsx files in the data directory\n",
    "xlsx_files = [f for f in os.listdir(data_dir) if f.endswith(\".xlsx\")]\n",
    "\n",
    "for file in xlsx_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=None)\n",
    "        for sheet_name, sheet_df in df.items():\n",
    "            # Replace spaces with underscores in filename\n",
    "            sanitized_filename = os.path.splitext(file)[0].replace(\" \", \"_\")\n",
    "            sanitized_sheet_name = sheet_name.replace(\" \", \"_\")\n",
    "            csv_filename = os.path.join(data_dir, f\"{sanitized_filename}_{sanitized_sheet_name}.csv\")\n",
    "\n",
    "            sheet_df.to_csv(csv_filename, index=False, sep=\",\", encoding=\"latin1\")\n",
    "            print(f\"Converted: {file} (Sheet: {sheet_name}) -> {csv_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OÖ 2013.xlsx contained 3 (hidden) sheets, which upon manual inspection, are not relevant and/or redundant for us. Therefore we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/OÖ_2013_whlsortgemnr.csv\n",
    "!rm data/OÖ_2013_MandateData.csv\n",
    "!rm data/OÖ_2013_WAHLDAT.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We now start with extracting the data from the CSV files. First, we initialize spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, when, lit, expr\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "# init spark\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"MunicipalSpendingAndElectionAnalysis\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import the data from the CSV files and clean them. We start with the spendings data:\n",
    "- we remove encoding issues we noticed upon manual inspection\n",
    "- we rename categories for readability and cast their type\n",
    "- we aggregate the spending data.\n",
    "    - we do this becuase the data is currently broken down into subcategories (e.g. spendings on preschool education, on physical education etc.)\n",
    "    - for some of the analysis we will use the total spending per municipality\n",
    "- we slugify using the helper function the municipality names so we can process them easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def standardize_municipality(col_name):\n",
    "    \"\"\"lowercase, trim, replace spaces with dashes (i.e. slugify)\"\"\"\n",
    "    return F.regexp_replace(F.lower(F.trim(F.col(col_name))), \" \", \"-\")\n",
    "\n",
    "\n",
    "# --- read & transform municipal spending data ---\n",
    "spending_csv = \"data/Bildungsausgaben_Gemeinden_Oberösterreich_data_2007_bis_2019.csv\"\n",
    "df_spending = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"encoding\", \"UTF-8\")\n",
    "    .csv(spending_csv)\n",
    ")\n",
    "\n",
    "# rename cols\n",
    "df_spending = (df_spending\n",
    "    .withColumnRenamed(\"Gemeinde\", \"Municipality\")\n",
    "    .withColumnRenamed(\"Year\", \"Year\")\n",
    "    .withColumnRenamed(\"Abschnitt\", \"Category\")\n",
    "    .withColumnRenamed(\"Betrag in Euro\", \"Spending\")\n",
    ")\n",
    "\n",
    "# replace chars in category\n",
    "df_spending = df_spending.withColumn(\n",
    "    \"Category\",\n",
    "    regexp_replace(col(\"Category\"), \"FĂ¶rderung\", \"Förderung\")\n",
    ")\n",
    "df_spending = df_spending.withColumn(\n",
    "    \"Category\",\n",
    "    regexp_replace(col(\"Category\"), \"Sport und auĂźerschulische Leibeserziehung\",\n",
    "                   \"Sport und außerschulische Leibeserziehung\")\n",
    ")\n",
    "\n",
    "# cast cols\n",
    "df_spending = df_spending.withColumn(\"Year\", col(\"Year\").cast(\"int\"))\n",
    "df_spending = df_spending.withColumn(\"Spending\", col(\"Spending\").cast(\"float\"))\n",
    "\n",
    "# aggregate spending\n",
    "df_spending_agg = (\n",
    "    df_spending\n",
    "    .groupBy(\"Municipality\", \"Year\")\n",
    "    .agg(F.sum(\"Spending\").alias(\"Spending_Summe\"))\n",
    ")\n",
    "\n",
    "# add lowercase municipality\n",
    "df_spending_agg = df_spending_agg.withColumn(\"Municipality_Lowercase\", standardize_municipality(\"Municipality\"))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we process the election data for the available years. We initialize an empty DataFrame with predefined columns to store the cleaned data. The predefined columns are consistent amongst Austrian election datasets. Therefore, this script would presumably work for any election data across Austria. For including other countries, at first, we would need to standardize their election data to this format.\n",
    "\n",
    "We read the CSV into Spark, standardize column names, and identify party vote columns. We convert party vote counts to integers and determine the winning party for each municipality, which we will use for predictive analysis later on. We also add a slugified version of the municipality name for consistency.\n",
    "\n",
    "Once cleaned, the election data is merged into a single DataFrame and joined with the spending data using slugified municipality name and year. Since spending data only covers 2007–2019, elections from 2024 are automatically excluded. However, upon adding recent spending data, 2024 would be automatically included without needing manual modification to this script. Finally, we save the merged dataset as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 2008\n",
      "Processing data for 2013\n",
      "Processing data for 2017\n",
      "Processing data for 2019\n",
      "Processing data for 2024\n",
      "Merged data sample:\n",
      "+----------------------+----+---------------+------------------------------+---------------+------------------+----------------+---------------+-------------+-------------------+\n",
      "|Municipality_Lowercase|Year|Municipality_ID|Municipality_Name             |Wahlberechtigte|abgegebene_Stimmen|gueltige_Stimmen|Wahlbeteiligung|Winning_Party|Spending_Summe     |\n",
      "+----------------------+----+---------------+------------------------------+---------------+------------------+----------------+---------------+-------------+-------------------+\n",
      "|linz                  |2008|40101          |Linz                          |142125         |96209             |94496           |67.69          |SPO          |1.203534975E8      |\n",
      "|steyr                 |2008|40201          |Steyr                         |28962          |20765             |20335           |71.7           |SPO          |3.377888836328125E7|\n",
      "|wels                  |2008|40301          |Wels                          |40994          |28803             |28288           |70.26          |SPO          |5.50799846875E7    |\n",
      "|aspach                |2008|40402          |Aspach                        |1869           |1390              |1346            |74.37          |OVP          |1433794.4849853516 |\n",
      "|auerbach              |2008|40403          |Auerbach                      |411            |310               |301             |75.43          |OVP          |160001.2024230957  |\n",
      "+----------------------+----+---------------+------------------------------+---------------+------------------+----------------+---------------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- read & transform election data ---\n",
    "election_yrs = [2008, 2013, 2017, 2019, 2024]\n",
    "all_election_df = spark.createDataFrame([], schema=\"Year INT, Municipality_ID STRING, Municipality_Name STRING, Wahlberechtigte INT, abgegebene_Stimmen INT, gueltige_Stimmen INT, Wahlbeteiligung STRING, Winning_Party STRING, Municipality_Lowercase STRING\")\n",
    "\n",
    "for year in election_yrs:\n",
    "    print(f\"Processing data for {year}\")\n",
    "    votes_file = f\"data/OÖ_{year}_Stimmen.csv\"\n",
    "\n",
    "    # skip if file missing\n",
    "    if not os.path.exists(votes_file):\n",
    "        print(f\"[WARNING] Missing CSV(s) for year {year} -> Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # read csv\n",
    "    votes_df = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"encoding\", \"latin1\")\n",
    "        .csv(votes_file)\n",
    "    )\n",
    "\n",
    "    # normalize col names\n",
    "    renamed_columns = {c: unidecode(c.strip()).replace(\" \", \"_\") for c in votes_df.columns}\n",
    "    votes_df = votes_df.selectExpr(*[f\"`{old}` as `{new}`\" for old, new in renamed_columns.items()])\n",
    "    \n",
    "    # identify party cols\n",
    "    party_columns = [c for c in votes_df.columns if c not in {\n",
    "        \"Nr.\", \"Name\", \"Wahlberechtigte\", \"abgegeb._Stimmen\", \"gultige\", \"Wahlbet.\", \"ungultige\"\n",
    "    }]\n",
    "\n",
    "    # rename cols\n",
    "    votes_df = votes_df.withColumnRenamed(\"Nr.\", \"Municipality_ID\")\n",
    "    votes_df = votes_df.withColumnRenamed(\"Name\", \"Municipality_Name\")\n",
    "    votes_df = votes_df.withColumnRenamed(\"Wahlberechtigte\", \"Wahlberechtigte\")\n",
    "    votes_df = votes_df.withColumnRenamed(\"abgegeb._Stimmen\", \"abgegebene_Stimmen\")\n",
    "    votes_df = votes_df.withColumnRenamed(\"gultige\", \"gueltige_Stimmen\")\n",
    "    votes_df = votes_df.withColumnRenamed(\"Wahlbet.\", \"Wahlbeteiligung\")\n",
    "\n",
    "    # cast party cols to int\n",
    "    for party_col in party_columns:\n",
    "        votes_df = votes_df.withColumn(f\"votes_{party_col}\", col(party_col).cast(\"int\"))\n",
    "\n",
    "    # determine win party\n",
    "    vote_cols = [F.coalesce(col(f\"votes_{party_col}\"), lit(0)) for party_col in party_columns]\n",
    "    votes_df = votes_df.withColumn(\"max_votes\", F.greatest(*vote_cols))\n",
    "\n",
    "    winning_party_cases = [when(col(\"max_votes\") == col(f\"votes_{party_col}\"), lit(party_col)) for party_col in party_columns]\n",
    "    votes_df = votes_df.withColumn(\"Winning_Party\", F.coalesce(*winning_party_cases))\n",
    "\n",
    "    # drop temp cols\n",
    "    for party_col in party_columns:\n",
    "        votes_df = votes_df.drop(f\"votes_{party_col}\")\n",
    "\n",
    "    votes_df = votes_df.drop(\"max_votes\")\n",
    "\n",
    "    # add year & municipality lowercase\n",
    "    votes_df = votes_df.withColumn(\"Year\", lit(year))\n",
    "    votes_df = votes_df.withColumn(\"Municipality_Lowercase\", standardize_municipality(\"Municipality_Name\"))\n",
    "    # filter for numeric municipality ids\n",
    "    votes_df = votes_df.filter(col(\"Municipality_ID\").rlike(\"^[0-9]+$\"))\n",
    "\n",
    "    # add to main df\n",
    "    all_election_df = all_election_df.unionByName(votes_df.select(\n",
    "        \"Year\", \"Municipality_ID\", \"Municipality_Name\", \"Wahlberechtigte\",\n",
    "        \"abgegebene_Stimmen\", \"gueltige_Stimmen\", \"Wahlbeteiligung\", \"Winning_Party\", \"Municipality_Lowercase\"\n",
    "    ))\n",
    "\n",
    "# --- merging and output ---\n",
    "# join dfs\n",
    "merged_df = all_election_df.join(df_spending_agg, on=[\"Municipality_Lowercase\", \"Year\"], how=\"inner\").drop(\"Municipality\")\n",
    "# write to csv\n",
    "merged_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").option(\"encoding\", \"latin1\").csv(\"data/merged_data.csv\")\n",
    "print(\"Merged data sample:\")\n",
    "merged_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
